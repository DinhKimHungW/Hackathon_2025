# ğŸ¤– HÆ°á»›ng dáº«n tÃ­ch há»£p AI vÃ o PortLink Chatbot

## ğŸ“‹ Tá»•ng quan

Dá»± Ã¡n Ä‘Ã£ Ä‘Æ°á»£c tÃ­ch há»£p **GitHub Models API** Ä‘á»ƒ chatbot cÃ³ thá»ƒ:
- âœ… Tráº£ lá»i cÃ¢u há»i dá»±a trÃªn dá»¯ liá»‡u thá»±c táº¿ cá»§a dá»± Ã¡n
- âœ… PhÃ¢n tÃ­ch conflicts vÃ  Ä‘á» xuáº¥t giáº£i phÃ¡p
- âœ… ÄÆ°a ra khuyáº¿n nghá»‹ tá»‘i Æ°u hÃ³a
- âœ… Há»— trá»£ tiáº¿ng Viá»‡t vÃ  tiáº¿ng Anh

## ğŸš€ CÃ¡ch láº¥y GitHub API Key (MIá»„N PHÃ)

### BÆ°á»›c 1: Táº¡o GitHub Personal Access Token

1. ÄÄƒng nháº­p GitHub: https://github.com
2. VÃ o Settings â†’ Developer settings â†’ Personal access tokens â†’ Tokens (classic)
   - Hoáº·c truy cáº­p trá»±c tiáº¿p: https://github.com/settings/tokens
3. Click "Generate new token" â†’ "Generate new token (classic)"
4. Äiá»n thÃ´ng tin:
   - **Note:** `PortLink AI Access`
   - **Expiration:** 90 days (hoáº·c No expiration)
   - **Select scopes:** Chá»‰ cáº§n tÃ­ch âœ… **"Read access to models"**
5. Click "Generate token"
6. **QUAN TRá»ŒNG:** Copy token ngay (chá»‰ hiá»ƒn thá»‹ 1 láº§n!)
   - Format: `github_pat_...` (dÃ i ~90 kÃ½ tá»±)

### BÆ°á»›c 2: Cáº¥u hÃ¬nh trong dá»± Ã¡n

Má»Ÿ file `backend/.env` vÃ  thÃªm:

```env
AI_API_KEY=github_pat_YOUR_TOKEN_HERE
AI_API_ENDPOINT=https://models.inference.ai.azure.com
AI_MODEL=gpt-4o-mini
```

**CÃ¡c model cÃ³ sáºµn MIá»„N PHÃ:**
- `gpt-4o-mini` - Nhanh, nháº¹, tá»‘t cho chatbot (khuyÃªn dÃ¹ng)
- `gpt-4o` - Máº¡nh hÆ¡n nhÆ°ng cháº­m hÆ¡n
- `Phi-3-medium-128k-instruct` - Microsoft Phi-3
- `Llama-3.1-405B-Instruct` - Meta Llama 3.1
- `Mistral-large-2407` - Mistral AI
- `Cohere-command-r-plus-08-2024` - Cohere

### BÆ°á»›c 3: Khá»Ÿi Ä‘á»™ng láº¡i Backend

```bash
cd backend
npm run start:dev
```

## ğŸ¯ CÃ¡ch sá»­ dá»¥ng AI trong Chatbot

### 1. Chat vá»›i AI (tá»± Ä‘á»™ng sá»­ dá»¥ng dá»¯ liá»‡u dá»± Ã¡n)

**Endpoint:** `POST /api/v1/chatbot/chat`

```json
{
  "message": "Hiá»‡n táº¡i cÃ³ bao nhiÃªu tÃ u Ä‘ang Ä‘áº­u á»Ÿ cáº£ng?"
}
```

**Response:**
```json
{
  "message": "Dá»±a trÃªn dá»¯ liá»‡u hiá»‡n táº¡i, cÃ³ 3 tÃ u Ä‘ang Ä‘áº­u á»Ÿ cáº£ng:\n\n1. MSC SARAH (Container Ship) - Berth A1\n2. MAERSK SEOUL (Container Ship) - Berth A2\n3. EVERGREEN MARINE (Bulk Carrier) - Berth B1\n\nTáº¥t cáº£ Ä‘á»u cÃ³ tráº¡ng thÃ¡i 'BERTHED' vÃ  dá»± kiáº¿n hoÃ n thÃ nh vÃ o ngÃ y mai.",
  "intent": "ai_powered_query",
  "data": {
    "confidence": 0.85,
    "dataSources": ["ship_visits", "schedules"]
  }
}
```

### 2. PhÃ¢n tÃ­ch Conflict vá»›i AI

**Endpoint:** `GET /api/v1/chatbot/ai/analyze-conflict/:conflictId`

```bash
curl http://localhost:3000/api/v1/chatbot/ai/analyze-conflict/uuid-here \
  -H "Authorization: Bearer YOUR_JWT_TOKEN"
```

**Response:**
```json
{
  "message": "**PhÃ¢n tÃ­ch Conflict:**\n\n**Root Cause:**\nXung Ä‘á»™t lá»‹ch trÃ¬nh do 2 tÃ u cÃ¹ng yÃªu cáº§u Berth A1 trong cÃ¹ng khung giá»...\n\n**Giáº£i phÃ¡p Ä‘á» xuáº¥t:**\n1. Di chuyá»ƒn tÃ u thá»© 2 sang Berth A2 (kháº£ thi 95%)\n2. HoÃ£n lá»‹ch tÃ u thá»© 2 thÃªm 2 giá» (kháº£ thi 80%)\n3. TÄƒng tá»‘c Ä‘á»™ xá»­ lÃ½ tÃ u thá»© 1 (kháº£ thi 60%)",
  "confidence": 0.85,
  "dataSources": ["conflicts", "schedules"]
}
```

### 3. Táº¡o Äá» xuáº¥t Tá»‘i Æ°u hÃ³a

**Endpoint:** `GET /api/v1/chatbot/ai/optimize-all`

```bash
curl http://localhost:3000/api/v1/chatbot/ai/optimize-all \
  -H "Authorization: Bearer YOUR_JWT_TOKEN"
```

## ğŸ“Š AI Service Architecture

```
User Query â†’ ChatbotService â†’ AIService
                                  â†“
                        1. Gather Project Data
                           - Ship Visits
                           - Schedules
                           - Conflicts
                           - Assets
                           - Tasks
                                  â†“
                        2. Build Context Prompt
                           - System Instructions
                           - Real Data
                           - User Query
                                  â†“
                        3. Call GitHub Models API
                           - OpenAI-compatible
                           - Streaming support
                                  â†“
                        4. Parse & Return Response
                           - Formatted answer
                           - Data sources used
                           - Confidence score
```

## ğŸ”§ Tuning AI Behavior

### Thay Ä‘á»•i Model (trong .env):

```env
# Nháº¹, nhanh - tá»‘t cho development
AI_MODEL=gpt-4o-mini

# Máº¡nh hÆ¡n - production
AI_MODEL=gpt-4o

# Open source models
AI_MODEL=Phi-3-medium-128k-instruct
AI_MODEL=Llama-3.1-405B-Instruct
```

### TÃ¹y chá»‰nh System Prompt (ai.service.ts):

Sá»­a method `buildPrompt()` Ä‘á»ƒ thay Ä‘á»•i hÃ nh vi cá»§a AI:

```typescript
const systemPrompt = `You are an intelligent assistant for PortLink...
**Your Role:**
- GiÃºp users quáº£n lÃ½ cáº£ng...
- LuÃ´n tráº£ lá»i báº±ng tiáº¿ng Viá»‡t (hoáº·c English náº¿u user há»i báº±ng English)
...`;
```

### Äiá»u chá»‰nh Parameters:

Trong method `callAI()`:

```typescript
{
  temperature: 0.7,  // 0.0-1.0: CÃ ng cao cÃ ng sÃ¡ng táº¡o
  max_tokens: 1000,  // Äá»™ dÃ i response
  top_p: 0.95,       // Sampling method
}
```

## ğŸ§ª Testing

### Test chat Ä‘Æ¡n giáº£n:

```bash
# Login trÆ°á»›c
curl -X POST http://localhost:3000/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email":"admin@catlai.com","password":"Admin@2025"}'

# Copy access_token tá»« response

# Test AI chat
curl -X POST http://localhost:3000/api/v1/chatbot/chat \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{"message":"HÃ£y tÃ³m táº¯t tÃ¬nh hÃ¬nh cáº£ng hiá»‡n táº¡i"}'
```

### Test vá»›i Frontend:

1. ÄÄƒng nháº­p vÃ o dashboard
2. Má»Ÿ trang Chat/Chatbot
3. Há»i cÃ¡c cÃ¢u nhÆ°:
   - "CÃ³ bao nhiÃªu tÃ u Ä‘ang Ä‘á»£i?"
   - "PhÃ¢n tÃ­ch conflict cho tÃ´i"
   - "Äá» xuáº¥t cÃ¡ch tá»‘i Æ°u hÃ³a"

## âš ï¸ LÆ°u Ã½ quan trá»ng

### Rate Limits (GitHub Models - Free Tier):
- **RPM (Requests per minute):** 15 requests/phÃºt
- **TPM (Tokens per minute):** 150,000 tokens/phÃºt
- **RPD (Requests per day):** 150 requests/ngÃ y

â†’ Äá»§ cho development vÃ  demo, nhÆ°ng nÃªn cache responses náº¿u production

### Security:
- âœ… KhÃ´ng commit `.env` lÃªn GitHub
- âœ… Token cÃ³ expiration date
- âœ… Revoke token ngay náº¿u bá»‹ lá»™
- âœ… Sá»­ dá»¥ng environment variables trong production

### Fallback:
- Náº¿u AI khÃ´ng kháº£ dá»¥ng (háº¿t quota, lá»—i API), chatbot tá»± Ä‘á»™ng fallback vá» logic cÅ©
- User váº«n nháº­n Ä‘Æ°á»£c response há»¯u Ã­ch

## ğŸ“š TÃ i liá»‡u tham kháº£o

- **GitHub Models:** https://github.com/marketplace/models
- **API Reference:** https://docs.github.com/en/rest/models
- **Model Catalog:** https://github.com/marketplace/models/catalog
- **OpenAI API Docs:** https://platform.openai.com/docs/api-reference

## ğŸ‰ Káº¿t quáº£

Sau khi cáº¥u hÃ¬nh xong, chatbot sáº½:
1. âœ… Hiá»ƒu ngá»¯ cáº£nh vÃ  tráº£ lá»i chÃ­nh xÃ¡c dá»±a trÃªn dá»¯ liá»‡u thá»±c
2. âœ… PhÃ¢n tÃ­ch conflicts vá»›i AI vÃ  Ä‘á» xuáº¥t giáº£i phÃ¡p
3. âœ… Tá»± Ä‘á»™ng gather data tá»« database khi cáº§n
4. âœ… Há»— trá»£ Ä‘a ngÃ´n ngá»¯ (Vietnamese & English)
5. âœ… CÃ³ fallback khi AI khÃ´ng kháº£ dá»¥ng

**Demo queries báº¡n cÃ³ thá»ƒ thá»­:**
- "TÃ u nÃ o sáº½ Ä‘áº¿n cáº£ng hÃ´m nay?"
- "CÃ³ conflict nÃ o cáº§n xá»­ lÃ½ khÃ´ng?"
- "Äá» xuáº¥t cÃ¡ch sá»­ dá»¥ng berth hiá»‡u quáº£ hÆ¡n"
- "PhÃ¢n tÃ­ch performance cá»§a crane"
- "What are the current bottlenecks?"

---

**Happy coding! ğŸš€**

Náº¿u cÃ³ váº¥n Ä‘á», check logs táº¡i terminal backend Ä‘á»ƒ debug.
